<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" /><meta name="generator" content="Docutils 0.18.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>neural_de.transformations package &mdash; neuralde 1.1.0 documentation</title>
      <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
      <link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
  <!--[if lt IE 9]>
    <script src="_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script src="_static/jquery.js?v=5d32c60e"></script>
        <script src="_static/_sphinx_javascript_frameworks_compat.js?v=2cd50e6c"></script>
        <script src="_static/documentation_options.js?v=fc837d61"></script>
        <script src="_static/doctools.js?v=888ff710"></script>
        <script src="_static/sphinx_highlight.js?v=dc90522c"></script>
        <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script src="_static/js/theme.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="neural_de.transformations.diffusion package" href="neural_de.transformations.diffusion.html" />
    <link rel="prev" title="neural_de.external.prenet package" href="neural_de.external.prenet.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="index.html" class="icon icon-home">
            neuralde
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Contents:</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="guidelines.html">üìñ Guidelines</a></li>
<li class="toctree-l1"><a class="reference internal" href="tech_docs.html">üìö Technical docs</a></li>
<li class="toctree-l1"><a class="reference internal" href="theory_overview.html">üí° Theory Overview</a></li>
<li class="toctree-l1"><a class="reference internal" href="changelog.html">üîÑ Changelog</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="modules.html">üé° Package neuralde</a><ul class="current">
<li class="toctree-l2 current"><a class="reference internal" href="neural_de.html">neural_de package</a><ul class="current">
<li class="toctree-l3 current"><a class="reference internal" href="neural_de.html#subpackages">Subpackages</a><ul class="current">
<li class="toctree-l4"><a class="reference internal" href="neural_de.external.html">neural_de.external package</a></li>
<li class="toctree-l4 current"><a class="current reference internal" href="#">neural_de.transformations package</a></li>
<li class="toctree-l4"><a class="reference internal" href="neural_de.utils.html">neural_de.utils package</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="neural_de.html#submodules">Submodules</a></li>
<li class="toctree-l3"><a class="reference internal" href="neural_de.html#module-neural_de.main">neural_de.main module</a></li>
<li class="toctree-l3"><a class="reference internal" href="neural_de.html#module-neural_de">Module contents</a></li>
</ul>
</li>
</ul>
</li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">neuralde</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="index.html" class="icon icon-home" aria-label="Home"></a></li>
          <li class="breadcrumb-item"><a href="modules.html">üé° Package neuralde</a></li>
          <li class="breadcrumb-item"><a href="neural_de.html">neural_de package</a></li>
      <li class="breadcrumb-item active">neural_de.transformations package</li>
      <li class="wy-breadcrumbs-aside">
            <a href="_sources/neural_de.transformations.rst.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="neural-de-transformations-package">
<h1>neural_de.transformations package<a class="headerlink" href="#neural-de-transformations-package" title="Link to this heading">ÔÉÅ</a></h1>
<section id="subpackages">
<h2>Subpackages<a class="headerlink" href="#subpackages" title="Link to this heading">ÔÉÅ</a></h2>
<div class="toctree-wrapper compound">
<ul>
<li class="toctree-l1"><a class="reference internal" href="neural_de.transformations.diffusion.html">neural_de.transformations.diffusion package</a><ul>
<li class="toctree-l2"><a class="reference internal" href="neural_de.transformations.diffusion.html#subpackages">Subpackages</a><ul>
<li class="toctree-l3"><a class="reference internal" href="neural_de.transformations.diffusion.unet.html">neural_de.transformations.diffusion.unet package</a><ul>
<li class="toctree-l4"><a class="reference internal" href="neural_de.transformations.diffusion.unet.html#submodules">Submodules</a></li>
<li class="toctree-l4"><a class="reference internal" href="neural_de.transformations.diffusion.unet.html#module-neural_de.transformations.diffusion.unet.attention_block">neural_de.transformations.diffusion.unet.attention_block module</a></li>
<li class="toctree-l4"><a class="reference internal" href="neural_de.transformations.diffusion.unet.html#module-neural_de.transformations.diffusion.unet.downsample">neural_de.transformations.diffusion.unet.downsample module</a></li>
<li class="toctree-l4"><a class="reference internal" href="neural_de.transformations.diffusion.unet.html#module-neural_de.transformations.diffusion.unet.nn">neural_de.transformations.diffusion.unet.nn module</a></li>
<li class="toctree-l4"><a class="reference internal" href="neural_de.transformations.diffusion.unet.html#module-neural_de.transformations.diffusion.unet.qkv_attention">neural_de.transformations.diffusion.unet.qkv_attention module</a></li>
<li class="toctree-l4"><a class="reference internal" href="neural_de.transformations.diffusion.unet.html#module-neural_de.transformations.diffusion.unet.qkv_attention_legacy">neural_de.transformations.diffusion.unet.qkv_attention_legacy module</a></li>
<li class="toctree-l4"><a class="reference internal" href="neural_de.transformations.diffusion.unet.html#module-neural_de.transformations.diffusion.unet.res_block">neural_de.transformations.diffusion.unet.res_block module</a></li>
<li class="toctree-l4"><a class="reference internal" href="neural_de.transformations.diffusion.unet.html#module-neural_de.transformations.diffusion.unet.timestep_block">neural_de.transformations.diffusion.unet.timestep_block module</a></li>
<li class="toctree-l4"><a class="reference internal" href="neural_de.transformations.diffusion.unet.html#module-neural_de.transformations.diffusion.unet.timestep_embed_sequential">neural_de.transformations.diffusion.unet.timestep_embed_sequential module</a></li>
<li class="toctree-l4"><a class="reference internal" href="neural_de.transformations.diffusion.unet.html#module-neural_de.transformations.diffusion.unet.unet_model">neural_de.transformations.diffusion.unet.unet_model module</a></li>
<li class="toctree-l4"><a class="reference internal" href="neural_de.transformations.diffusion.unet.html#module-neural_de.transformations.diffusion.unet.upsample">neural_de.transformations.diffusion.unet.upsample module</a></li>
<li class="toctree-l4"><a class="reference internal" href="neural_de.transformations.diffusion.unet.html#module-neural_de.transformations.diffusion.unet.utils">neural_de.transformations.diffusion.unet.utils module</a></li>
<li class="toctree-l4"><a class="reference internal" href="neural_de.transformations.diffusion.unet.html#module-neural_de.transformations.diffusion.unet">Module contents</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="neural_de.transformations.diffusion.html#submodules">Submodules</a></li>
<li class="toctree-l2"><a class="reference internal" href="neural_de.transformations.diffusion.html#module-neural_de.transformations.diffusion.diffpure_config">neural_de.transformations.diffusion.diffpure_config module</a><ul>
<li class="toctree-l3"><a class="reference internal" href="neural_de.transformations.diffusion.html#neural_de.transformations.diffusion.diffpure_config.DiffPureConfig"><code class="docutils literal notranslate"><span class="pre">DiffPureConfig</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="neural_de.transformations.diffusion.html#neural_de.transformations.diffusion.diffpure_config.DiffPureConfig.weights_path"><code class="docutils literal notranslate"><span class="pre">DiffPureConfig.weights_path</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="neural_de.transformations.diffusion.html#neural_de.transformations.diffusion.diffpure_config.DiffPureConfig.img_shape"><code class="docutils literal notranslate"><span class="pre">DiffPureConfig.img_shape</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="neural_de.transformations.diffusion.html#neural_de.transformations.diffusion.diffpure_config.DiffPureConfig.attention_resolutions"><code class="docutils literal notranslate"><span class="pre">DiffPureConfig.attention_resolutions</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="neural_de.transformations.diffusion.html#neural_de.transformations.diffusion.diffpure_config.DiffPureConfig.num_classes"><code class="docutils literal notranslate"><span class="pre">DiffPureConfig.num_classes</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="neural_de.transformations.diffusion.html#neural_de.transformations.diffusion.diffpure_config.DiffPureConfig.dims"><code class="docutils literal notranslate"><span class="pre">DiffPureConfig.dims</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="neural_de.transformations.diffusion.html#neural_de.transformations.diffusion.diffpure_config.DiffPureConfig.learn_sigma"><code class="docutils literal notranslate"><span class="pre">DiffPureConfig.learn_sigma</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="neural_de.transformations.diffusion.html#neural_de.transformations.diffusion.diffpure_config.DiffPureConfig.num_channels"><code class="docutils literal notranslate"><span class="pre">DiffPureConfig.num_channels</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="neural_de.transformations.diffusion.html#neural_de.transformations.diffusion.diffpure_config.DiffPureConfig.num_head_channels"><code class="docutils literal notranslate"><span class="pre">DiffPureConfig.num_head_channels</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="neural_de.transformations.diffusion.html#neural_de.transformations.diffusion.diffpure_config.DiffPureConfig.num_res_blocks"><code class="docutils literal notranslate"><span class="pre">DiffPureConfig.num_res_blocks</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="neural_de.transformations.diffusion.html#neural_de.transformations.diffusion.diffpure_config.DiffPureConfig.resblock_updown"><code class="docutils literal notranslate"><span class="pre">DiffPureConfig.resblock_updown</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="neural_de.transformations.diffusion.html#neural_de.transformations.diffusion.diffpure_config.DiffPureConfig.use_fp16"><code class="docutils literal notranslate"><span class="pre">DiffPureConfig.use_fp16</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="neural_de.transformations.diffusion.html#neural_de.transformations.diffusion.diffpure_config.DiffPureConfig.use_scale_shift_norm"><code class="docutils literal notranslate"><span class="pre">DiffPureConfig.use_scale_shift_norm</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="neural_de.transformations.diffusion.html#neural_de.transformations.diffusion.diffpure_config.DiffPureConfig.num_heads"><code class="docutils literal notranslate"><span class="pre">DiffPureConfig.num_heads</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="neural_de.transformations.diffusion.html#neural_de.transformations.diffusion.diffpure_config.DiffPureConfig.num_heads_upsample"><code class="docutils literal notranslate"><span class="pre">DiffPureConfig.num_heads_upsample</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="neural_de.transformations.diffusion.html#neural_de.transformations.diffusion.diffpure_config.DiffPureConfig.channel_mult"><code class="docutils literal notranslate"><span class="pre">DiffPureConfig.channel_mult</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="neural_de.transformations.diffusion.html#neural_de.transformations.diffusion.diffpure_config.DiffPureConfig.dropout"><code class="docutils literal notranslate"><span class="pre">DiffPureConfig.dropout</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="neural_de.transformations.diffusion.html#neural_de.transformations.diffusion.diffpure_config.DiffPureConfig.use_new_attention_order"><code class="docutils literal notranslate"><span class="pre">DiffPureConfig.use_new_attention_order</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="neural_de.transformations.diffusion.html#neural_de.transformations.diffusion.diffpure_config.DiffPureConfig.t"><code class="docutils literal notranslate"><span class="pre">DiffPureConfig.t</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="neural_de.transformations.diffusion.html#neural_de.transformations.diffusion.diffpure_config.DiffPureConfig.t_delta"><code class="docutils literal notranslate"><span class="pre">DiffPureConfig.t_delta</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="neural_de.transformations.diffusion.html#neural_de.transformations.diffusion.diffpure_config.DiffPureConfig.use_bm"><code class="docutils literal notranslate"><span class="pre">DiffPureConfig.use_bm</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="neural_de.transformations.diffusion.html#neural_de.transformations.diffusion.diffpure_config.DiffPureConfig.use_checkpoint"><code class="docutils literal notranslate"><span class="pre">DiffPureConfig.use_checkpoint</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="neural_de.transformations.diffusion.html#neural_de.transformations.diffusion.diffpure_config.DiffPureConfig.conv_resample"><code class="docutils literal notranslate"><span class="pre">DiffPureConfig.conv_resample</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="neural_de.transformations.diffusion.html#neural_de.transformations.diffusion.diffpure_config.DiffPureConfig.sample_step"><code class="docutils literal notranslate"><span class="pre">DiffPureConfig.sample_step</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="neural_de.transformations.diffusion.html#neural_de.transformations.diffusion.diffpure_config.DiffPureConfig.rand_t"><code class="docutils literal notranslate"><span class="pre">DiffPureConfig.rand_t</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="neural_de.transformations.diffusion.html#id0"><code class="docutils literal notranslate"><span class="pre">DiffPureConfig.attention_resolutions</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="neural_de.transformations.diffusion.html#id1"><code class="docutils literal notranslate"><span class="pre">DiffPureConfig.channel_mult</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="neural_de.transformations.diffusion.html#id2"><code class="docutils literal notranslate"><span class="pre">DiffPureConfig.conv_resample</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="neural_de.transformations.diffusion.html#id3"><code class="docutils literal notranslate"><span class="pre">DiffPureConfig.dims</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="neural_de.transformations.diffusion.html#id4"><code class="docutils literal notranslate"><span class="pre">DiffPureConfig.dropout</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="neural_de.transformations.diffusion.html#id5"><code class="docutils literal notranslate"><span class="pre">DiffPureConfig.img_shape</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="neural_de.transformations.diffusion.html#id6"><code class="docutils literal notranslate"><span class="pre">DiffPureConfig.learn_sigma</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="neural_de.transformations.diffusion.html#id7"><code class="docutils literal notranslate"><span class="pre">DiffPureConfig.num_channels</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="neural_de.transformations.diffusion.html#id8"><code class="docutils literal notranslate"><span class="pre">DiffPureConfig.num_classes</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="neural_de.transformations.diffusion.html#id9"><code class="docutils literal notranslate"><span class="pre">DiffPureConfig.num_head_channels</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="neural_de.transformations.diffusion.html#id10"><code class="docutils literal notranslate"><span class="pre">DiffPureConfig.num_heads</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="neural_de.transformations.diffusion.html#id11"><code class="docutils literal notranslate"><span class="pre">DiffPureConfig.num_heads_upsample</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="neural_de.transformations.diffusion.html#id12"><code class="docutils literal notranslate"><span class="pre">DiffPureConfig.num_res_blocks</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="neural_de.transformations.diffusion.html#id13"><code class="docutils literal notranslate"><span class="pre">DiffPureConfig.rand_t</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="neural_de.transformations.diffusion.html#id14"><code class="docutils literal notranslate"><span class="pre">DiffPureConfig.resblock_updown</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="neural_de.transformations.diffusion.html#id15"><code class="docutils literal notranslate"><span class="pre">DiffPureConfig.sample_step</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="neural_de.transformations.diffusion.html#id16"><code class="docutils literal notranslate"><span class="pre">DiffPureConfig.t</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="neural_de.transformations.diffusion.html#id17"><code class="docutils literal notranslate"><span class="pre">DiffPureConfig.t_delta</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="neural_de.transformations.diffusion.html#id18"><code class="docutils literal notranslate"><span class="pre">DiffPureConfig.use_bm</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="neural_de.transformations.diffusion.html#id19"><code class="docutils literal notranslate"><span class="pre">DiffPureConfig.use_checkpoint</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="neural_de.transformations.diffusion.html#id20"><code class="docutils literal notranslate"><span class="pre">DiffPureConfig.use_fp16</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="neural_de.transformations.diffusion.html#id21"><code class="docutils literal notranslate"><span class="pre">DiffPureConfig.use_new_attention_order</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="neural_de.transformations.diffusion.html#id22"><code class="docutils literal notranslate"><span class="pre">DiffPureConfig.use_scale_shift_norm</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="neural_de.transformations.diffusion.html#id23"><code class="docutils literal notranslate"><span class="pre">DiffPureConfig.weights_path</span></code></a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="neural_de.transformations.diffusion.html#module-neural_de.transformations.diffusion.diffusion_enhancer">neural_de.transformations.diffusion.diffusion_enhancer module</a><ul>
<li class="toctree-l3"><a class="reference internal" href="neural_de.transformations.diffusion.html#neural_de.transformations.diffusion.diffusion_enhancer.DiffusionEnhancer"><code class="docutils literal notranslate"><span class="pre">DiffusionEnhancer</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="neural_de.transformations.diffusion.html#neural_de.transformations.diffusion.diffusion_enhancer.DiffusionEnhancer.forward"><code class="docutils literal notranslate"><span class="pre">DiffusionEnhancer.forward()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="neural_de.transformations.diffusion.html#neural_de.transformations.diffusion.diffusion_enhancer.DiffusionEnhancer.transform"><code class="docutils literal notranslate"><span class="pre">DiffusionEnhancer.transform()</span></code></a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="neural_de.transformations.diffusion.html#module-neural_de.transformations.diffusion.rev_guided_diffusion">neural_de.transformations.diffusion.rev_guided_diffusion module</a><ul>
<li class="toctree-l3"><a class="reference internal" href="neural_de.transformations.diffusion.html#neural_de.transformations.diffusion.rev_guided_diffusion.RevGuidedDiffusion"><code class="docutils literal notranslate"><span class="pre">RevGuidedDiffusion</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="neural_de.transformations.diffusion.html#neural_de.transformations.diffusion.rev_guided_diffusion.RevGuidedDiffusion.image_editing_sample"><code class="docutils literal notranslate"><span class="pre">RevGuidedDiffusion.image_editing_sample()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="neural_de.transformations.diffusion.html#neural_de.transformations.diffusion.rev_guided_diffusion.RevGuidedDiffusion.training"><code class="docutils literal notranslate"><span class="pre">RevGuidedDiffusion.training</span></code></a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="neural_de.transformations.diffusion.html#module-neural_de.transformations.diffusion.rev_vpsde">neural_de.transformations.diffusion.rev_vpsde module</a><ul>
<li class="toctree-l3"><a class="reference internal" href="neural_de.transformations.diffusion.html#neural_de.transformations.diffusion.rev_vpsde.RevVPSDE"><code class="docutils literal notranslate"><span class="pre">RevVPSDE</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="neural_de.transformations.diffusion.html#neural_de.transformations.diffusion.rev_vpsde.RevVPSDE.f"><code class="docutils literal notranslate"><span class="pre">RevVPSDE.f()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="neural_de.transformations.diffusion.html#neural_de.transformations.diffusion.rev_vpsde.RevVPSDE.g"><code class="docutils literal notranslate"><span class="pre">RevVPSDE.g()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="neural_de.transformations.diffusion.html#neural_de.transformations.diffusion.rev_vpsde.RevVPSDE.rvpsde_fn"><code class="docutils literal notranslate"><span class="pre">RevVPSDE.rvpsde_fn()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="neural_de.transformations.diffusion.html#neural_de.transformations.diffusion.rev_vpsde.RevVPSDE.training"><code class="docutils literal notranslate"><span class="pre">RevVPSDE.training</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="neural_de.transformations.diffusion.html#neural_de.transformations.diffusion.rev_vpsde.RevVPSDE.vpsde_fn"><code class="docutils literal notranslate"><span class="pre">RevVPSDE.vpsde_fn()</span></code></a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="neural_de.transformations.diffusion.html#module-neural_de.transformations.diffusion">Module contents</a></li>
</ul>
</li>
</ul>
</div>
</section>
<section id="submodules">
<h2>Submodules<a class="headerlink" href="#submodules" title="Link to this heading">ÔÉÅ</a></h2>
</section>
<section id="module-neural_de.transformations.brightness_enhancer">
<span id="neural-de-transformations-brightness-enhancer-module"></span><h2>neural_de.transformations.brightness_enhancer module<a class="headerlink" href="#module-neural_de.transformations.brightness_enhancer" title="Link to this heading">ÔÉÅ</a></h2>
<p>Image brightness enhancement method.</p>
<dl class="py class">
<dt class="sig sig-object py" id="neural_de.transformations.brightness_enhancer.BrightnessEnhancer">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">neural_de.transformations.brightness_enhancer.</span></span><span class="sig-name descname"><span class="pre">BrightnessEnhancer</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">logger</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/neural_de/transformations/brightness_enhancer.html#BrightnessEnhancer"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#neural_de.transformations.brightness_enhancer.BrightnessEnhancer" title="Link to this definition">ÔÉÅ</a></dt>
<dd><p>Bases: <a class="reference internal" href="#neural_de.transformations.transformation.BaseTransformation" title="neural_de.transformations.transformation.BaseTransformation"><code class="xref py py-class docutils literal notranslate"><span class="pre">BaseTransformation</span></code></a></p>
<p>BaseTransformation method for image brightness change.
It uses NPLIE-based method for brightness enhancement, and Opencv for transforming the
image.</p>
<p>Example :</p>
<p>See the notebook <cite>examples/BrightnessEnhancer_example.ipynb</cite> for more usage details.</p>
<p>1- Import the class</p>
<p>. code-block:: python</p>
<p>from neural_de.transformations import BrightnessEnhancer</p>
<p>2- Create an instance of BrightnessEnhancer.</p>
<p>. code-block:: python</p>
<p>bright_ehn = BrightnessEnhancer()</p>
<p>3- Apply the brightness change to a batch of images to a given shape</p>
<p>. code-block:: python</p>
<p>out_images = bright_ehn.transform(images)</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>logger</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">Logger</span></code>]) ‚Äì It is recommended to use the Confiance logger, obtainable with</p></li>
<li><p><strong>neural_de.utils.get_logger</strong> ‚Äì </p></li>
<li><p><strong>None</strong> (<em>If</em>) ‚Äì </p></li>
<li><p><strong>provided.</strong> (<em>one logging with stdout will be</em>) ‚Äì </p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="neural_de.transformations.brightness_enhancer.BrightnessEnhancer.enhance_brightness">
<span class="sig-name descname"><span class="pre">enhance_brightness</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">image</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/neural_de/transformations/brightness_enhancer.html#BrightnessEnhancer.enhance_brightness"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#neural_de.transformations.brightness_enhancer.BrightnessEnhancer.enhance_brightness" title="Link to this definition">ÔÉÅ</a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>Image</strong> ‚Äì numpy array format with float32 dtype.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Image numpy array format with float32 dtype.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="neural_de.transformations.brightness_enhancer.BrightnessEnhancer.transform">
<span class="sig-name descname"><span class="pre">transform</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">images</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/neural_de/transformations/brightness_enhancer.html#BrightnessEnhancer.transform"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#neural_de.transformations.brightness_enhancer.BrightnessEnhancer.transform" title="Link to this definition">ÔÉÅ</a></dt>
<dd><p>Improve brightness a batch of images using a NPLIE-based method.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>images</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">list</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">ndarray</span></code>], <code class="xref py py-class docutils literal notranslate"><span class="pre">ndarray</span></code>]) ‚Äì Batch of images. Each image should be of a <code class="docutils literal notranslate"><span class="pre">np.ndarray</span></code> of target_shape <em>(h,w,
channels)</em>. Images dimensions do not need to be the same across the batch.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>The same images with improved brightness.</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>
<section id="module-neural_de.transformations.centered_zoom">
<span id="neural-de-transformations-centered-zoom-module"></span><h2>neural_de.transformations.centered_zoom module<a class="headerlink" href="#module-neural_de.transformations.centered_zoom" title="Link to this heading">ÔÉÅ</a></h2>
<p>Simple wrapper to share experimental results on working params for a CenteredZoom</p>
<dl class="py class">
<dt class="sig sig-object py" id="neural_de.transformations.centered_zoom.CenteredZoom">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">neural_de.transformations.centered_zoom.</span></span><span class="sig-name descname"><span class="pre">CenteredZoom</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">keep_ratio</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">logger</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/neural_de/transformations/centered_zoom.html#CenteredZoom"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#neural_de.transformations.centered_zoom.CenteredZoom" title="Link to this definition">ÔÉÅ</a></dt>
<dd><p>Bases: <a class="reference internal" href="#neural_de.transformations.transformation.BaseTransformation" title="neural_de.transformations.transformation.BaseTransformation"><code class="xref py py-class docutils literal notranslate"><span class="pre">BaseTransformation</span></code></a></p>
<p>CenteredZoom image transformation based on a numpy implementation.
Given a batch of 3-channels image of size width x height, return the centered tile of size
width*keep_ratio x height*keep_ratio.
This transformation does not perform any resolution enhancement of the returned content.
See ResolutionEnhancer to perform both crop and resolution enhancement.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>keep_ratio</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code>) ‚Äì The proportion of the input image we keep. Must be in ]0,1[.</p></li>
<li><p><strong>logger</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">Logger</span></code>]) ‚Äì It is recommended to use the Confiance logger, obtainable with
neural_de.utils.get_logger(‚Ä¶). If None, one logging with stdout will be provided.</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="neural_de.transformations.centered_zoom.CenteredZoom.transform">
<span class="sig-name descname"><span class="pre">transform</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">images</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/neural_de/transformations/centered_zoom.html#CenteredZoom.transform"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#neural_de.transformations.centered_zoom.CenteredZoom.transform" title="Link to this definition">ÔÉÅ</a></dt>
<dd><p>Apply CenteredZoom to a batch of images using numpy slicing method.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>images</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">list</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">ndarray</span></code>], <code class="xref py py-class docutils literal notranslate"><span class="pre">ndarray</span></code>]) ‚Äì Batch of images. Each image should be of a <code class="docutils literal notranslate"><span class="pre">np.ndarray</span></code> of target_shape <em>(h,w,
channels)</em>. Images dimensions do not need to be the same across the batch.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>The images zoomed to a given ratio in respect to its center.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="neural_de.transformations.centered_zoom.CenteredZoom.transform_with_annotations">
<span class="sig-name descname"><span class="pre">transform_with_annotations</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">images</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">bbox</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/neural_de/transformations/centered_zoom.html#CenteredZoom.transform_with_annotations"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#neural_de.transformations.centered_zoom.CenteredZoom.transform_with_annotations" title="Link to this definition">ÔÉÅ</a></dt>
<dd><p>Transform bounding boxes to the reference in the new zoomed image.
:type images: <code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">list</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">ndarray</span></code>], <code class="xref py py-class docutils literal notranslate"><span class="pre">ndarray</span></code>]
:param images: Batch of images. Each image should be of a <code class="docutils literal notranslate"><span class="pre">np.ndarray</span></code> of target_shape <em>(h,w,
:param channels)</em>. Images dimensions do not need to be the same across the batch.:
:type bbox: <code class="xref py py-class docutils literal notranslate"><span class="pre">list</span></code>
:param bbox: list of list of list [batch_dim, nb_object_per_image, [x1, y1, x2, y2]]
:param with the x1:
:param y1:
:param x2:
:param y2 bounding box position in the original image.:</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p><p>The images zoomed to a given ratio in respect to its center.
The list of <code class="docutils literal notranslate"><span class="pre">np.ndarray</span></code> with the x1, y1, x2, y2 bounding box position in the zoomed</p>
<blockquote>
<div><p>image.</p>
</div></blockquote>
</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>
<section id="module-neural_de.transformations.de_rain_enhancer">
<span id="neural-de-transformations-de-rain-enhancer-module"></span><h2>neural_de.transformations.de_rain_enhancer module<a class="headerlink" href="#module-neural_de.transformations.de_rain_enhancer" title="Link to this heading">ÔÉÅ</a></h2>
<p>DeRain enhancer</p>
<dl class="py class">
<dt class="sig sig-object py" id="neural_de.transformations.de_rain_enhancer.DeRainConfig">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">neural_de.transformations.de_rain_enhancer.</span></span><span class="sig-name descname"><span class="pre">DeRainConfig</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">upsample_mode</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'bilinear'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ngf</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">64</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_blocks</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">9</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">use_dropout</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">input_nc</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">3</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_nc</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">3</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">padding_type</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'reflect'</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/neural_de/transformations/de_rain_enhancer.html#DeRainConfig"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#neural_de.transformations.de_rain_enhancer.DeRainConfig" title="Link to this definition">ÔÉÅ</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></p>
<p>Interal configuration of the DeRain enhancer.</p>
<dl class="py attribute">
<dt class="sig sig-object py" id="neural_de.transformations.de_rain_enhancer.DeRainConfig.input_nc">
<span class="sig-name descname"><span class="pre">input_nc</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">3</span></em><a class="headerlink" href="#neural_de.transformations.de_rain_enhancer.DeRainConfig.input_nc" title="Link to this definition">ÔÉÅ</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="neural_de.transformations.de_rain_enhancer.DeRainConfig.n_blocks">
<span class="sig-name descname"><span class="pre">n_blocks</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">9</span></em><a class="headerlink" href="#neural_de.transformations.de_rain_enhancer.DeRainConfig.n_blocks" title="Link to this definition">ÔÉÅ</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="neural_de.transformations.de_rain_enhancer.DeRainConfig.ngf">
<span class="sig-name descname"><span class="pre">ngf</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">64</span></em><a class="headerlink" href="#neural_de.transformations.de_rain_enhancer.DeRainConfig.ngf" title="Link to this definition">ÔÉÅ</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="neural_de.transformations.de_rain_enhancer.DeRainConfig.output_nc">
<span class="sig-name descname"><span class="pre">output_nc</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">3</span></em><a class="headerlink" href="#neural_de.transformations.de_rain_enhancer.DeRainConfig.output_nc" title="Link to this definition">ÔÉÅ</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="neural_de.transformations.de_rain_enhancer.DeRainConfig.padding_type">
<span class="sig-name descname"><span class="pre">padding_type</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">'reflect'</span></em><a class="headerlink" href="#neural_de.transformations.de_rain_enhancer.DeRainConfig.padding_type" title="Link to this definition">ÔÉÅ</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="neural_de.transformations.de_rain_enhancer.DeRainConfig.upsample_mode">
<span class="sig-name descname"><span class="pre">upsample_mode</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">'bilinear'</span></em><a class="headerlink" href="#neural_de.transformations.de_rain_enhancer.DeRainConfig.upsample_mode" title="Link to this definition">ÔÉÅ</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="neural_de.transformations.de_rain_enhancer.DeRainConfig.use_dropout">
<span class="sig-name descname"><span class="pre">use_dropout</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">False</span></em><a class="headerlink" href="#neural_de.transformations.de_rain_enhancer.DeRainConfig.use_dropout" title="Link to this definition">ÔÉÅ</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="neural_de.transformations.de_rain_enhancer.DeRainEnhancer">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">neural_de.transformations.de_rain_enhancer.</span></span><span class="sig-name descname"><span class="pre">DeRainEnhancer</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">device</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'cpu'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">logger</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/neural_de/transformations/de_rain_enhancer.html#DeRainEnhancer"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#neural_de.transformations.de_rain_enhancer.DeRainEnhancer" title="Link to this definition">ÔÉÅ</a></dt>
<dd><p>Bases: <a class="reference internal" href="#neural_de.transformations.transformation.BaseTransformation" title="neural_de.transformations.transformation.BaseTransformation"><code class="xref py py-class docutils literal notranslate"><span class="pre">BaseTransformation</span></code></a></p>
<p>Provides a rain removal image transformation using the GT-Rain Derain Model.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>device</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>) ‚Äì Any torch-compatible device string.</p></li>
<li><p><strong>logger</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">Logger</span></code>]) ‚Äì It is recommended to use the Confiance logger, obtainable with
neural_de.utils.get_logger(‚Ä¶). If None, one logging with stdout will be provided.</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="neural_de.transformations.de_rain_enhancer.DeRainEnhancer.transform">
<span class="sig-name descname"><span class="pre">transform</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">images</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/neural_de/transformations/de_rain_enhancer.html#DeRainEnhancer.transform"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#neural_de.transformations.de_rain_enhancer.DeRainEnhancer.transform" title="Link to this definition">ÔÉÅ</a></dt>
<dd><p>Removes the rain in a batch of images. It differs from style transfer, as it does not remove
pools and ground reflection. The outputs are as ‚Äúas if the rained just stop
falling‚Äù.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>images</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">list</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">ndarray</span></code>], <code class="xref py py-class docutils literal notranslate"><span class="pre">ndarray</span></code>]) ‚Äì Batch of images. Each image should be of a <code class="docutils literal notranslate"><span class="pre">np.ndarray</span></code> of target_shape <em>(h,w,
channels)</em>. Images dimensions should be identical across one batch.</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">ndarray</span></code></p>
</dd>
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>The same images without rain falling on it.</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>
<section id="module-neural_de.transformations.de_snow_enhancer">
<span id="neural-de-transformations-de-snow-enhancer-module"></span><h2>neural_de.transformations.de_snow_enhancer module<a class="headerlink" href="#module-neural_de.transformations.de_snow_enhancer" title="Link to this heading">ÔÉÅ</a></h2>
<p>Snow removal enhancer - Prenet Based implementation</p>
<dl class="py class">
<dt class="sig sig-object py" id="neural_de.transformations.de_snow_enhancer.DeSnowEnhancer">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">neural_de.transformations.de_snow_enhancer.</span></span><span class="sig-name descname"><span class="pre">DeSnowEnhancer</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">device</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'cpu'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">logger</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/neural_de/transformations/de_snow_enhancer.html#DeSnowEnhancer"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#neural_de.transformations.de_snow_enhancer.DeSnowEnhancer" title="Link to this definition">ÔÉÅ</a></dt>
<dd><p>Bases: <a class="reference internal" href="#neural_de.transformations.transformation.BaseTransformation" title="neural_de.transformations.transformation.BaseTransformation"><code class="xref py py-class docutils literal notranslate"><span class="pre">BaseTransformation</span></code></a></p>
<p>Snow Removal Enhancer, Prenet based implementation.</p>
<p>** WARNING ** : The current method may have bad results on real images. The model had been trained
on a simulated dataset, thus if the dataset is so different of the trained dataset, the results are not guaranteed.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>device</strong> ‚Äì Any torch-compatible device string.</p></li>
<li><p><strong>logger</strong> ‚Äì It is recommended to use the Confiance logger, obtainable with
neural_de.utils.get_logger(‚Ä¶). If None, one logging with stdout will be provided.</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="neural_de.transformations.de_snow_enhancer.DeSnowEnhancer.transform">
<span class="sig-name descname"><span class="pre">transform</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">images</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/neural_de/transformations/de_snow_enhancer.html#DeSnowEnhancer.transform"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#neural_de.transformations.de_snow_enhancer.DeSnowEnhancer.transform" title="Link to this definition">ÔÉÅ</a></dt>
<dd><p>Removes the snow in a batch of images.</p>
<p><strong>WARNING</strong> : The current method may have bad results on real images.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>images</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">ndarray</span></code>) ‚Äì Batch of images. Each image should be of a <code class="docutils literal notranslate"><span class="pre">np.ndarray</span></code> of target_shape <em>(h,w,
channels)</em>. Images dimensions should be identical across one batch.</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">ndarray</span></code></p>
</dd>
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>The same images without snow on it.</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>
<section id="module-neural_de.transformations.kernel_deblurring_enhancer">
<span id="neural-de-transformations-kernel-deblurring-enhancer-module"></span><h2>neural_de.transformations.kernel_deblurring_enhancer module<a class="headerlink" href="#module-neural_de.transformations.kernel_deblurring_enhancer" title="Link to this heading">ÔÉÅ</a></h2>
<p>Simple wrapper to share experimental results on working params for a Deblurring Kernel</p>
<dl class="py class">
<dt class="sig sig-object py" id="neural_de.transformations.kernel_deblurring_enhancer.KernelDeblurringEnhancer">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">neural_de.transformations.kernel_deblurring_enhancer.</span></span><span class="sig-name descname"><span class="pre">KernelDeblurringEnhancer</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">kernel</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'high'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">custom_kernel</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">logger</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/neural_de/transformations/kernel_deblurring_enhancer.html#KernelDeblurringEnhancer"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#neural_de.transformations.kernel_deblurring_enhancer.KernelDeblurringEnhancer" title="Link to this definition">ÔÉÅ</a></dt>
<dd><p>Bases: <a class="reference internal" href="#neural_de.transformations.transformation.BaseTransformation" title="neural_de.transformations.transformation.BaseTransformation"><code class="xref py py-class docutils literal notranslate"><span class="pre">BaseTransformation</span></code></a></p>
<p>Kernel Deblurring image transformation based on OpenCv implementation. Provides pre-set
filter of medium and high intensity.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>kernel</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>) ‚Äì <code class="docutils literal notranslate"><span class="pre">high</span></code> or <code class="docutils literal notranslate"><span class="pre">medium</span></code>: use a pre-set kernel with high or medium intensity.</p></li>
<li><p><strong>custom</strong> ‚Äì Optional, custom kernel to use. It can be any non empty 2D matrix. If provided,
the value of <cite>kernel</cite> will not be used.</p></li>
<li><p><strong>logger</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">Logger</span></code>]) ‚Äì It is recommended to use the Confiance logger, obtainable with
neural_de.utils.get_logger(‚Ä¶). If None, one logging with stdout will be provided.</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="neural_de.transformations.kernel_deblurring_enhancer.KernelDeblurringEnhancer.transform">
<span class="sig-name descname"><span class="pre">transform</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">images</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/neural_de/transformations/kernel_deblurring_enhancer.html#KernelDeblurringEnhancer.transform"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#neural_de.transformations.kernel_deblurring_enhancer.KernelDeblurringEnhancer.transform" title="Link to this definition">ÔÉÅ</a></dt>
<dd><p>Deblur a batch of images using a Kernel-based method.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>images</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">list</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">ndarray</span></code>], <code class="xref py py-class docutils literal notranslate"><span class="pre">ndarray</span></code>]) ‚Äì Batch of images. Each image should be of a <code class="docutils literal notranslate"><span class="pre">np.ndarray</span></code> of target_shape <em>(h,w,
channels)</em>. Images dimensions do not need to be the same across the batch.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>The same images with less blurr.</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>
<section id="module-neural_de.transformations.night_image_enhancer">
<span id="neural-de-transformations-night-image-enhancer-module"></span><h2>neural_de.transformations.night_image_enhancer module<a class="headerlink" href="#module-neural_de.transformations.night_image_enhancer" title="Link to this heading">ÔÉÅ</a></h2>
<p>Night to day enhancer - Maxim based implementation</p>
<dl class="py class">
<dt class="sig sig-object py" id="neural_de.transformations.night_image_enhancer.NightConfig">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">neural_de.transformations.night_image_enhancer.</span></span><span class="sig-name descname"><span class="pre">NightConfig</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">variant</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'S-2'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dropout_rate</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_outputs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">3</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">use_bias</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_supervision_scales</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">3</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/neural_de/transformations/night_image_enhancer.html#NightConfig"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#neural_de.transformations.night_image_enhancer.NightConfig" title="Link to this definition">ÔÉÅ</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></p>
<p>Static Enhancer configuration</p>
<dl class="py attribute">
<dt class="sig sig-object py" id="neural_de.transformations.night_image_enhancer.NightConfig.dropout_rate">
<span class="sig-name descname"><span class="pre">dropout_rate</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">0.0</span></em><a class="headerlink" href="#neural_de.transformations.night_image_enhancer.NightConfig.dropout_rate" title="Link to this definition">ÔÉÅ</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="neural_de.transformations.night_image_enhancer.NightConfig.num_outputs">
<span class="sig-name descname"><span class="pre">num_outputs</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">3</span></em><a class="headerlink" href="#neural_de.transformations.night_image_enhancer.NightConfig.num_outputs" title="Link to this definition">ÔÉÅ</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="neural_de.transformations.night_image_enhancer.NightConfig.num_supervision_scales">
<span class="sig-name descname"><span class="pre">num_supervision_scales</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">3</span></em><a class="headerlink" href="#neural_de.transformations.night_image_enhancer.NightConfig.num_supervision_scales" title="Link to this definition">ÔÉÅ</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="neural_de.transformations.night_image_enhancer.NightConfig.use_bias">
<span class="sig-name descname"><span class="pre">use_bias</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">True</span></em><a class="headerlink" href="#neural_de.transformations.night_image_enhancer.NightConfig.use_bias" title="Link to this definition">ÔÉÅ</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="neural_de.transformations.night_image_enhancer.NightConfig.variant">
<span class="sig-name descname"><span class="pre">variant</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">'S-2'</span></em><a class="headerlink" href="#neural_de.transformations.night_image_enhancer.NightConfig.variant" title="Link to this definition">ÔÉÅ</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="neural_de.transformations.night_image_enhancer.NightImageEnhancer">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">neural_de.transformations.night_image_enhancer.</span></span><span class="sig-name descname"><span class="pre">NightImageEnhancer</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">device</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'cpu'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">logger</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/neural_de/transformations/night_image_enhancer.html#NightImageEnhancer"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#neural_de.transformations.night_image_enhancer.NightImageEnhancer" title="Link to this definition">ÔÉÅ</a></dt>
<dd><p>Bases: <a class="reference internal" href="#neural_de.transformations.transformation.BaseTransformation" title="neural_de.transformations.transformation.BaseTransformation"><code class="xref py py-class docutils literal notranslate"><span class="pre">BaseTransformation</span></code></a></p>
<p>Provides Night to Day image transformation using the MAXIM model.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>logger</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">Logger</span></code>]) ‚Äì It is recommended to use the Confiance logger, obtainable with
neural_de.utils.get_logger(‚Ä¶). If None, one logging with stdout will be provided.</p>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="neural_de.transformations.night_image_enhancer.NightImageEnhancer.transform">
<span class="sig-name descname"><span class="pre">transform</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">images</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/neural_de/transformations/night_image_enhancer.html#NightImageEnhancer.transform"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#neural_de.transformations.night_image_enhancer.NightImageEnhancer.transform" title="Link to this definition">ÔÉÅ</a></dt>
<dd><p>Transform a batch of night image into ‚Äúday images‚Äù, ie the same image but looking
as if taken in daylight.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>images</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">list</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">ndarray</span></code>], <code class="xref py py-class docutils literal notranslate"><span class="pre">ndarray</span></code>]) ‚Äì Batch of images. Each image should be of a <code class="docutils literal notranslate"><span class="pre">np.ndarray</span></code> of target_shape <em>(h,w,
channels)</em>.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>The same images transformed as if taken in daylight.</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>
<section id="module-neural_de.transformations.resolution_enhancer">
<span id="neural-de-transformations-resolution-enhancer-module"></span><h2>neural_de.transformations.resolution_enhancer module<a class="headerlink" href="#module-neural_de.transformations.resolution_enhancer" title="Link to this heading">ÔÉÅ</a></h2>
<p>Implementation of the ResolutionEnhancer method.</p>
<dl class="py attribute">
<dt class="sig sig-object py" id="neural_de.transformations.resolution_enhancer.UPSCALE_MODEL">
<span class="sig-prename descclassname"><span class="pre">neural_de.transformations.resolution_enhancer.</span></span><span class="sig-name descname"><span class="pre">UPSCALE_MODEL</span></span><a class="headerlink" href="#neural_de.transformations.resolution_enhancer.UPSCALE_MODEL" title="Link to this definition">ÔÉÅ</a></dt>
<dd><p>version of the transformer model used for image upscaling</p>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="neural_de.transformations.resolution_enhancer.ResolutionEnhancer">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">neural_de.transformations.resolution_enhancer.</span></span><span class="sig-name descname"><span class="pre">ResolutionEnhancer</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">device</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'cpu'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">logger</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/neural_de/transformations/resolution_enhancer.html#ResolutionEnhancer"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#neural_de.transformations.resolution_enhancer.ResolutionEnhancer" title="Link to this definition">ÔÉÅ</a></dt>
<dd><p>Bases: <a class="reference internal" href="#neural_de.transformations.transformation.BaseTransformation" title="neural_de.transformations.transformation.BaseTransformation"><code class="xref py py-class docutils literal notranslate"><span class="pre">BaseTransformation</span></code></a></p>
<p>BaseTransformation method for image resolution change.
It uses neural-based method for resolution enhancement, and Opencv for diminishing the
resolution.</p>
<dl>
<dt>Example :</dt><dd><p>See the notebook <cite>examples/ResolutionEnhancer_example.ipynb</cite> for more usage details.</p>
<p>1- Import the class</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">neural_de.transformations</span><span class="w"> </span><span class="kn">import</span> <span class="n">ResolutionEnhancer</span>
</pre></div>
</div>
<p>2- Create an instance of ResolutionEnhancer.
<code class="docutils literal notranslate"><span class="pre">device</span> <span class="pre">=&quot;Cuda&quot;</span></code> is recommended if you have a gpu and torch with cuda enabled.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">res_shift</span> <span class="o">=</span> <span class="n">ResolutionEnhancer</span><span class="p">(</span><span class="n">device</span><span class="o">=</span> <span class="s2">&quot;cpu&quot;</span><span class="p">)</span>
</pre></div>
</div>
<p>3- Apply the resolution change to a batch of images to a given shape</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">out_images</span> <span class="o">=</span> <span class="n">res_shift</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">images</span><span class="p">,</span> <span class="n">ratio</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
</pre></div>
</div>
</dd>
</dl>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>device</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>) ‚Äì Any torch-compatible device string.</p></li>
<li><p><strong>logger</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">Logger</span></code>]) ‚Äì It is recommended to use the Confiance logger, obtainable with
neural_de.utils.get_logger(‚Ä¶). If None, one logging with stdout will be provided.</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="neural_de.transformations.resolution_enhancer.ResolutionEnhancer.transform">
<span class="sig-name descname"><span class="pre">transform</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">images</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">target_shape</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">crop_ratio</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.0</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/neural_de/transformations/resolution_enhancer.html#ResolutionEnhancer.transform"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#neural_de.transformations.resolution_enhancer.ResolutionEnhancer.transform" title="Link to this definition">ÔÉÅ</a></dt>
<dd><p>Modify the resolution of a batch of images to a given target_shape.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>images</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">list</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">ndarray</span></code>], <code class="xref py py-class docutils literal notranslate"><span class="pre">ndarray</span></code>]) ‚Äì Batch of images. Each image should be of a <code class="docutils literal notranslate"><span class="pre">np.ndarray</span></code> of target_shape <em>(h,w,
channels)</em></p></li>
<li><p><strong>target_shape</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">list</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">tuple</span></code>]) ‚Äì New resolution (h,w) in pixel.</p></li>
<li><p><strong>crop_ratio</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code>) ‚Äì image cropping ratio (range in [0., 1.[)</p></li>
</ul>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">ndarray</span></code></p>
</dd>
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>Images with new resolution.</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>
<section id="module-neural_de.transformations.transformation">
<span id="neural-de-transformations-transformation-module"></span><h2>neural_de.transformations.transformation module<a class="headerlink" href="#module-neural_de.transformations.transformation" title="Link to this heading">ÔÉÅ</a></h2>
<p>Parent class for any transformation method.</p>
<dl class="py class">
<dt class="sig sig-object py" id="neural_de.transformations.transformation.BaseTransformation">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">neural_de.transformations.transformation.</span></span><span class="sig-name descname"><span class="pre">BaseTransformation</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">logger</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/neural_de/transformations/transformation.html#BaseTransformation"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#neural_de.transformations.transformation.BaseTransformation" title="Link to this definition">ÔÉÅ</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></p>
<p>Parent class for any transformation methods of the library.
Provides the methods for logging and input validation.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>logger</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">Logger</span></code>]) ‚Äì logging.logger. It is recommended to use the Confiance one, obtainable with
neural_de.utils.get_logger(‚Ä¶)</p>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="neural_de.transformations.transformation.BaseTransformation.check_device_validity">
<span class="sig-name descname"><span class="pre">check_device_validity</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">device</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'cpu'</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/neural_de/transformations/transformation.html#BaseTransformation.check_device_validity"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#neural_de.transformations.transformation.BaseTransformation.check_device_validity" title="Link to this definition">ÔÉÅ</a></dt>
<dd><p>Check if the selected device is valid.
:type device: <code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>
:param device: str - cpu / cuda</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>None</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>
<section id="module-neural_de.transformations.transformation_pipeline">
<span id="neural-de-transformations-transformation-pipeline-module"></span><h2>neural_de.transformations.transformation_pipeline module<a class="headerlink" href="#module-neural_de.transformations.transformation_pipeline" title="Link to this heading">ÔÉÅ</a></h2>
<p>Transformation pipeline for automation of multiple transformations methods</p>
<dl class="py class">
<dt class="sig sig-object py" id="neural_de.transformations.transformation_pipeline.TransformationPipeline">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">neural_de.transformations.transformation_pipeline.</span></span><span class="sig-name descname"><span class="pre">TransformationPipeline</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">config</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">logger</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/neural_de/transformations/transformation_pipeline.html#TransformationPipeline"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#neural_de.transformations.transformation_pipeline.TransformationPipeline" title="Link to this definition">ÔÉÅ</a></dt>
<dd><p>Bases: <a class="reference internal" href="#neural_de.transformations.transformation.BaseTransformation" title="neural_de.transformations.transformation.BaseTransformation"><code class="xref py py-class docutils literal notranslate"><span class="pre">BaseTransformation</span></code></a></p>
<p>Provides a pipeline object, to facilitate the automation of multiple transformations methods,
and/or offer loading from a yaml file.</p>
<p>You can check the example notebook <strong>examples/Pipeline_example.ipynb</strong> for details on the syntax
and usage.
An example of valid config file can be found in <strong>examples/config/conf_user.yaml</strong></p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>config</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">list</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">Path</span></code>]) ‚Äì either a path toward a yaml configuration file, or a list of dict.</p></li>
<li><p><strong>logger</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">Logger</span></code>]) ‚Äì It is recommended to use the confiance.ai logger, obtainable with
neural_de.utils.get_logger(‚Ä¶). If None, one logging with stdout will be provided.</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="neural_de.transformations.transformation_pipeline.TransformationPipeline.transform">
<span class="sig-name descname"><span class="pre">transform</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">images</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/neural_de/transformations/transformation_pipeline.html#TransformationPipeline.transform"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#neural_de.transformations.transformation_pipeline.TransformationPipeline.transform" title="Link to this definition">ÔÉÅ</a></dt>
<dd><p>Sequentially apply every method of the pipeline on a batch of image, and returns
the resulting images.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>images</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">list</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">ndarray</span></code>]) ‚Äì Batch of images. Each image should be of a <code class="docutils literal notranslate"><span class="pre">np.ndarray</span></code> of target_shape <em>(h,w,
channels)</em></p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">list</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">ndarray</span></code>]</p>
</dd>
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>Resulting batch of images, one per image provided.</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="neural_de.transformations.transformation_pipeline.camel_to_snake">
<span class="sig-prename descclassname"><span class="pre">neural_de.transformations.transformation_pipeline.</span></span><span class="sig-name descname"><span class="pre">camel_to_snake</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">s</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/neural_de/transformations/transformation_pipeline.html#camel_to_snake"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#neural_de.transformations.transformation_pipeline.camel_to_snake" title="Link to this definition">ÔÉÅ</a></dt>
<dd><p>This function convert input strings s from Camelcase format to snake case format</p>
</dd></dl>

</section>
<section id="module-neural_de.transformations">
<span id="module-contents"></span><h2>Module contents<a class="headerlink" href="#module-neural_de.transformations" title="Link to this heading">ÔÉÅ</a></h2>
<p>Module with the main images transformations methods of the neural_de library.
You can find more on how to use any of the proposed method in <code class="docutils literal notranslate"><span class="pre">./examples</span></code>, or in the method‚Äôs
class documentation.</p>
<dl class="simple">
<dt>List of the available methods :</dt><dd><ul class="simple">
<li><p>ResolutionEnhancer: enhance image resolution</p></li>
<li><p>NightImageEnhancer: transform night images into daylight ones</p></li>
<li><p>KernelDeblurringEnhancer: Improve blurry images</p></li>
<li><p>DeSnowEnhancer: Removes snow from images</p></li>
<li><p>DeRainEnhancer: Removes rain from images</p></li>
<li><p>BrightnessEnhancer: Improves image brightness</p></li>
<li><p>CenteredZoom: Centered crop of an image at a given ratio</p></li>
<li><p>DiffusionEnhancer : Enhance the image using diffusion-based denoising</p></li>
</ul>
</dd>
<dt>Special methods :</dt><dd><ul class="simple">
<li><p>TransformationPipeline : Allows the automation of any combination of the previous methods,
and loading from file.</p></li>
</ul>
</dd>
</dl>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="neural_de.external.prenet.html" class="btn btn-neutral float-left" title="neural_de.external.prenet package" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="neural_de.transformations.diffusion.html" class="btn btn-neutral float-right" title="neural_de.transformations.diffusion package" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2025, IRT-SystemX.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>