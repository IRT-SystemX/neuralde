<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" /><meta name="generator" content="Docutils 0.18.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>neural_de.transformations.diffusion package &mdash; neuralde 1.1.0 documentation</title>
      <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
      <link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
  <!--[if lt IE 9]>
    <script src="_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script src="_static/jquery.js?v=5d32c60e"></script>
        <script src="_static/_sphinx_javascript_frameworks_compat.js?v=2cd50e6c"></script>
        <script src="_static/documentation_options.js?v=fc837d61"></script>
        <script src="_static/doctools.js?v=888ff710"></script>
        <script src="_static/sphinx_highlight.js?v=dc90522c"></script>
        <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script src="_static/js/theme.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="neural_de.transformations.diffusion.unet package" href="neural_de.transformations.diffusion.unet.html" />
    <link rel="prev" title="neural_de.transformations package" href="neural_de.transformations.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="index.html" class="icon icon-home">
            neuralde
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Contents:</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="guidelines.html">📖 Guidelines</a></li>
<li class="toctree-l1"><a class="reference internal" href="tech_docs.html">📚 Technical docs</a></li>
<li class="toctree-l1"><a class="reference internal" href="theory_overview.html">💡 Theory Overview</a></li>
<li class="toctree-l1"><a class="reference internal" href="changelog.html">🔄 Changelog</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="modules.html">🎡 Package neural_de</a><ul class="current">
<li class="toctree-l2 current"><a class="reference internal" href="neural_de.html">neural_de package</a><ul class="current">
<li class="toctree-l3 current"><a class="reference internal" href="neural_de.html#subpackages">Subpackages</a><ul class="current">
<li class="toctree-l4"><a class="reference internal" href="neural_de.external.html">neural_de.external package</a></li>
<li class="toctree-l4 current"><a class="reference internal" href="neural_de.transformations.html">neural_de.transformations package</a></li>
<li class="toctree-l4"><a class="reference internal" href="neural_de.utils.html">neural_de.utils package</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="neural_de.html#submodules">Submodules</a></li>
<li class="toctree-l3"><a class="reference internal" href="neural_de.html#module-neural_de.main">neural_de.main module</a></li>
<li class="toctree-l3"><a class="reference internal" href="neural_de.html#module-neural_de">Module contents</a></li>
</ul>
</li>
</ul>
</li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">neuralde</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="index.html" class="icon icon-home" aria-label="Home"></a></li>
          <li class="breadcrumb-item"><a href="modules.html">🎡 Package neural_de</a></li>
          <li class="breadcrumb-item"><a href="neural_de.html">neural_de package</a></li>
          <li class="breadcrumb-item"><a href="neural_de.transformations.html">neural_de.transformations package</a></li>
      <li class="breadcrumb-item active">neural_de.transformations.diffusion package</li>
      <li class="wy-breadcrumbs-aside">
            <a href="_sources/neural_de.transformations.diffusion.rst.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="neural-de-transformations-diffusion-package">
<h1>neural_de.transformations.diffusion package<a class="headerlink" href="#neural-de-transformations-diffusion-package" title="Link to this heading"></a></h1>
<section id="subpackages">
<h2>Subpackages<a class="headerlink" href="#subpackages" title="Link to this heading"></a></h2>
<div class="toctree-wrapper compound">
<ul>
<li class="toctree-l1"><a class="reference internal" href="neural_de.transformations.diffusion.unet.html">neural_de.transformations.diffusion.unet package</a><ul>
<li class="toctree-l2"><a class="reference internal" href="neural_de.transformations.diffusion.unet.html#submodules">Submodules</a></li>
<li class="toctree-l2"><a class="reference internal" href="neural_de.transformations.diffusion.unet.html#module-neural_de.transformations.diffusion.unet.attention_block">neural_de.transformations.diffusion.unet.attention_block module</a><ul>
<li class="toctree-l3"><a class="reference internal" href="neural_de.transformations.diffusion.unet.html#neural_de.transformations.diffusion.unet.attention_block.AttentionBlock"><code class="docutils literal notranslate"><span class="pre">AttentionBlock</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="neural_de.transformations.diffusion.unet.html#neural_de.transformations.diffusion.unet.attention_block.AttentionBlock.forward"><code class="docutils literal notranslate"><span class="pre">AttentionBlock.forward()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="neural_de.transformations.diffusion.unet.html#neural_de.transformations.diffusion.unet.attention_block.AttentionBlock.training"><code class="docutils literal notranslate"><span class="pre">AttentionBlock.training</span></code></a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="neural_de.transformations.diffusion.unet.html#module-neural_de.transformations.diffusion.unet.downsample">neural_de.transformations.diffusion.unet.downsample module</a><ul>
<li class="toctree-l3"><a class="reference internal" href="neural_de.transformations.diffusion.unet.html#neural_de.transformations.diffusion.unet.downsample.Downsample"><code class="docutils literal notranslate"><span class="pre">Downsample</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="neural_de.transformations.diffusion.unet.html#neural_de.transformations.diffusion.unet.downsample.Downsample.forward"><code class="docutils literal notranslate"><span class="pre">Downsample.forward()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="neural_de.transformations.diffusion.unet.html#neural_de.transformations.diffusion.unet.downsample.Downsample.training"><code class="docutils literal notranslate"><span class="pre">Downsample.training</span></code></a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="neural_de.transformations.diffusion.unet.html#module-neural_de.transformations.diffusion.unet.nn">neural_de.transformations.diffusion.unet.nn module</a><ul>
<li class="toctree-l3"><a class="reference internal" href="neural_de.transformations.diffusion.unet.html#neural_de.transformations.diffusion.unet.nn.CheckpointFunction"><code class="docutils literal notranslate"><span class="pre">CheckpointFunction</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="neural_de.transformations.diffusion.unet.html#neural_de.transformations.diffusion.unet.nn.CheckpointFunction.backward"><code class="docutils literal notranslate"><span class="pre">CheckpointFunction.backward()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="neural_de.transformations.diffusion.unet.html#neural_de.transformations.diffusion.unet.nn.CheckpointFunction.forward"><code class="docutils literal notranslate"><span class="pre">CheckpointFunction.forward()</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="neural_de.transformations.diffusion.unet.html#neural_de.transformations.diffusion.unet.nn.GroupNorm32"><code class="docutils literal notranslate"><span class="pre">GroupNorm32</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="neural_de.transformations.diffusion.unet.html#neural_de.transformations.diffusion.unet.nn.GroupNorm32.affine"><code class="docutils literal notranslate"><span class="pre">GroupNorm32.affine</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="neural_de.transformations.diffusion.unet.html#neural_de.transformations.diffusion.unet.nn.GroupNorm32.eps"><code class="docutils literal notranslate"><span class="pre">GroupNorm32.eps</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="neural_de.transformations.diffusion.unet.html#neural_de.transformations.diffusion.unet.nn.GroupNorm32.forward"><code class="docutils literal notranslate"><span class="pre">GroupNorm32.forward()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="neural_de.transformations.diffusion.unet.html#neural_de.transformations.diffusion.unet.nn.GroupNorm32.num_channels"><code class="docutils literal notranslate"><span class="pre">GroupNorm32.num_channels</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="neural_de.transformations.diffusion.unet.html#neural_de.transformations.diffusion.unet.nn.GroupNorm32.num_groups"><code class="docutils literal notranslate"><span class="pre">GroupNorm32.num_groups</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="neural_de.transformations.diffusion.unet.html#neural_de.transformations.diffusion.unet.nn.avg_pool_nd"><code class="docutils literal notranslate"><span class="pre">avg_pool_nd()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="neural_de.transformations.diffusion.unet.html#neural_de.transformations.diffusion.unet.nn.checkpoint"><code class="docutils literal notranslate"><span class="pre">checkpoint()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="neural_de.transformations.diffusion.unet.html#neural_de.transformations.diffusion.unet.nn.conv_nd"><code class="docutils literal notranslate"><span class="pre">conv_nd()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="neural_de.transformations.diffusion.unet.html#neural_de.transformations.diffusion.unet.nn.linear"><code class="docutils literal notranslate"><span class="pre">linear()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="neural_de.transformations.diffusion.unet.html#neural_de.transformations.diffusion.unet.nn.normalization"><code class="docutils literal notranslate"><span class="pre">normalization()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="neural_de.transformations.diffusion.unet.html#neural_de.transformations.diffusion.unet.nn.timestep_embedding"><code class="docutils literal notranslate"><span class="pre">timestep_embedding()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="neural_de.transformations.diffusion.unet.html#neural_de.transformations.diffusion.unet.nn.zero_module"><code class="docutils literal notranslate"><span class="pre">zero_module()</span></code></a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="neural_de.transformations.diffusion.unet.html#module-neural_de.transformations.diffusion.unet.qkv_attention">neural_de.transformations.diffusion.unet.qkv_attention module</a><ul>
<li class="toctree-l3"><a class="reference internal" href="neural_de.transformations.diffusion.unet.html#neural_de.transformations.diffusion.unet.qkv_attention.QKVAttention"><code class="docutils literal notranslate"><span class="pre">QKVAttention</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="neural_de.transformations.diffusion.unet.html#neural_de.transformations.diffusion.unet.qkv_attention.QKVAttention.forward"><code class="docutils literal notranslate"><span class="pre">QKVAttention.forward()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="neural_de.transformations.diffusion.unet.html#neural_de.transformations.diffusion.unet.qkv_attention.QKVAttention.training"><code class="docutils literal notranslate"><span class="pre">QKVAttention.training</span></code></a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="neural_de.transformations.diffusion.unet.html#module-neural_de.transformations.diffusion.unet.qkv_attention_legacy">neural_de.transformations.diffusion.unet.qkv_attention_legacy module</a><ul>
<li class="toctree-l3"><a class="reference internal" href="neural_de.transformations.diffusion.unet.html#neural_de.transformations.diffusion.unet.qkv_attention_legacy.QKVAttentionLegacy"><code class="docutils literal notranslate"><span class="pre">QKVAttentionLegacy</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="neural_de.transformations.diffusion.unet.html#neural_de.transformations.diffusion.unet.qkv_attention_legacy.QKVAttentionLegacy.forward"><code class="docutils literal notranslate"><span class="pre">QKVAttentionLegacy.forward()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="neural_de.transformations.diffusion.unet.html#neural_de.transformations.diffusion.unet.qkv_attention_legacy.QKVAttentionLegacy.training"><code class="docutils literal notranslate"><span class="pre">QKVAttentionLegacy.training</span></code></a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="neural_de.transformations.diffusion.unet.html#module-neural_de.transformations.diffusion.unet.res_block">neural_de.transformations.diffusion.unet.res_block module</a><ul>
<li class="toctree-l3"><a class="reference internal" href="neural_de.transformations.diffusion.unet.html#neural_de.transformations.diffusion.unet.res_block.ResBlock"><code class="docutils literal notranslate"><span class="pre">ResBlock</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="neural_de.transformations.diffusion.unet.html#neural_de.transformations.diffusion.unet.res_block.ResBlock.forward"><code class="docutils literal notranslate"><span class="pre">ResBlock.forward()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="neural_de.transformations.diffusion.unet.html#neural_de.transformations.diffusion.unet.res_block.ResBlock.training"><code class="docutils literal notranslate"><span class="pre">ResBlock.training</span></code></a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="neural_de.transformations.diffusion.unet.html#module-neural_de.transformations.diffusion.unet.timestep_block">neural_de.transformations.diffusion.unet.timestep_block module</a><ul>
<li class="toctree-l3"><a class="reference internal" href="neural_de.transformations.diffusion.unet.html#neural_de.transformations.diffusion.unet.timestep_block.TimestepBlock"><code class="docutils literal notranslate"><span class="pre">TimestepBlock</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="neural_de.transformations.diffusion.unet.html#neural_de.transformations.diffusion.unet.timestep_block.TimestepBlock.forward"><code class="docutils literal notranslate"><span class="pre">TimestepBlock.forward()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="neural_de.transformations.diffusion.unet.html#neural_de.transformations.diffusion.unet.timestep_block.TimestepBlock.training"><code class="docutils literal notranslate"><span class="pre">TimestepBlock.training</span></code></a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="neural_de.transformations.diffusion.unet.html#module-neural_de.transformations.diffusion.unet.timestep_embed_sequential">neural_de.transformations.diffusion.unet.timestep_embed_sequential module</a><ul>
<li class="toctree-l3"><a class="reference internal" href="neural_de.transformations.diffusion.unet.html#neural_de.transformations.diffusion.unet.timestep_embed_sequential.TimestepEmbedSequential"><code class="docutils literal notranslate"><span class="pre">TimestepEmbedSequential</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="neural_de.transformations.diffusion.unet.html#neural_de.transformations.diffusion.unet.timestep_embed_sequential.TimestepEmbedSequential.forward"><code class="docutils literal notranslate"><span class="pre">TimestepEmbedSequential.forward()</span></code></a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="neural_de.transformations.diffusion.unet.html#module-neural_de.transformations.diffusion.unet.unet_model">neural_de.transformations.diffusion.unet.unet_model module</a><ul>
<li class="toctree-l3"><a class="reference internal" href="neural_de.transformations.diffusion.unet.html#neural_de.transformations.diffusion.unet.unet_model.UNetModel"><code class="docutils literal notranslate"><span class="pre">UNetModel</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="neural_de.transformations.diffusion.unet.html#neural_de.transformations.diffusion.unet.unet_model.UNetModel.convert_to_fp16"><code class="docutils literal notranslate"><span class="pre">UNetModel.convert_to_fp16()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="neural_de.transformations.diffusion.unet.html#neural_de.transformations.diffusion.unet.unet_model.UNetModel.convert_to_fp32"><code class="docutils literal notranslate"><span class="pre">UNetModel.convert_to_fp32()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="neural_de.transformations.diffusion.unet.html#neural_de.transformations.diffusion.unet.unet_model.UNetModel.forward"><code class="docutils literal notranslate"><span class="pre">UNetModel.forward()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="neural_de.transformations.diffusion.unet.html#neural_de.transformations.diffusion.unet.unet_model.UNetModel.training"><code class="docutils literal notranslate"><span class="pre">UNetModel.training</span></code></a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="neural_de.transformations.diffusion.unet.html#module-neural_de.transformations.diffusion.unet.upsample">neural_de.transformations.diffusion.unet.upsample module</a><ul>
<li class="toctree-l3"><a class="reference internal" href="neural_de.transformations.diffusion.unet.html#neural_de.transformations.diffusion.unet.upsample.Upsample"><code class="docutils literal notranslate"><span class="pre">Upsample</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="neural_de.transformations.diffusion.unet.html#neural_de.transformations.diffusion.unet.upsample.Upsample.forward"><code class="docutils literal notranslate"><span class="pre">Upsample.forward()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="neural_de.transformations.diffusion.unet.html#neural_de.transformations.diffusion.unet.upsample.Upsample.training"><code class="docutils literal notranslate"><span class="pre">Upsample.training</span></code></a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="neural_de.transformations.diffusion.unet.html#module-neural_de.transformations.diffusion.unet.utils">neural_de.transformations.diffusion.unet.utils module</a><ul>
<li class="toctree-l3"><a class="reference internal" href="neural_de.transformations.diffusion.unet.html#neural_de.transformations.diffusion.unet.utils.convert_module_to_f16"><code class="docutils literal notranslate"><span class="pre">convert_module_to_f16()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="neural_de.transformations.diffusion.unet.html#neural_de.transformations.diffusion.unet.utils.convert_module_to_f32"><code class="docutils literal notranslate"><span class="pre">convert_module_to_f32()</span></code></a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="neural_de.transformations.diffusion.unet.html#module-neural_de.transformations.diffusion.unet">Module contents</a></li>
</ul>
</li>
</ul>
</div>
</section>
<section id="submodules">
<h2>Submodules<a class="headerlink" href="#submodules" title="Link to this heading"></a></h2>
</section>
<section id="module-neural_de.transformations.diffusion.diffpure_config">
<span id="neural-de-transformations-diffusion-diffpure-config-module"></span><h2>neural_de.transformations.diffusion.diffpure_config module<a class="headerlink" href="#module-neural_de.transformations.diffusion.diffpure_config" title="Link to this heading"></a></h2>
<dl class="py class">
<dt class="sig sig-object py" id="neural_de.transformations.diffusion.diffpure_config.DiffPureConfig">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">neural_de.transformations.diffusion.diffpure_config.</span></span><span class="sig-name descname"><span class="pre">DiffPureConfig</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">weights_path=PosixPath('/home/runner/.neuralde/diffpure/256x256_diffusion_uncond.pt')</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">img_shape=(3</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">256</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">256)</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">attention_resolutions=&lt;factory&gt;</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_classes=None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dims=2</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">learn_sigma=True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_channels=256</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_head_channels=64</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_res_blocks=2</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">resblock_updown=True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">use_fp16=True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">use_scale_shift_norm=True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_heads=4</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_heads_upsample=-1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">channel_mult=None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dropout=0.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">use_new_attention_order=False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">t=150</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">t_delta=15</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">use_bm=False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">use_checkpoint=False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">conv_resample=True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sample_step=1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">rand_t=False</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/neural_de/transformations/diffusion/diffpure_config.html#DiffPureConfig"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#neural_de.transformations.diffusion.diffpure_config.DiffPureConfig" title="Link to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></p>
<p>A dataclass to configure and provide parameters for the internal diffusion model of
diffusion_enhancer.</p>
<p>Most of the parameters are available to allow a custom usage of a different pre-trained
diffusion models, based on the U-net architecture and code.
The one which can be modified with the provided model are t, t_delta and sample_steps.</p>
<dl class="py attribute">
<dt class="sig sig-object py" id="neural_de.transformations.diffusion.diffpure_config.DiffPureConfig.weights_path">
<span class="sig-name descname"><span class="pre">weights_path</span></span><a class="headerlink" href="#neural_de.transformations.diffusion.diffpure_config.DiffPureConfig.weights_path" title="Link to this definition"></a></dt>
<dd><p>Path of the pre-trained weights, to provide custom weights files.</p>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="neural_de.transformations.diffusion.diffpure_config.DiffPureConfig.img_shape">
<span class="sig-name descname"><span class="pre">img_shape</span></span><a class="headerlink" href="#neural_de.transformations.diffusion.diffpure_config.DiffPureConfig.img_shape" title="Link to this definition"></a></dt>
<dd><p>the shape of each input image of the diffusion model (by default (3, 256, 256)).
Dimension are hannel-first.</p>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="neural_de.transformations.diffusion.diffpure_config.DiffPureConfig.attention_resolutions">
<span class="sig-name descname"><span class="pre">attention_resolutions</span></span><a class="headerlink" href="#neural_de.transformations.diffusion.diffpure_config.DiffPureConfig.attention_resolutions" title="Link to this definition"></a></dt>
<dd><p>resolution, in pixels, of the attention-layers of the model</p>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="neural_de.transformations.diffusion.diffpure_config.DiffPureConfig.num_classes">
<span class="sig-name descname"><span class="pre">num_classes</span></span><a class="headerlink" href="#neural_de.transformations.diffusion.diffpure_config.DiffPureConfig.num_classes" title="Link to this definition"></a></dt>
<dd><p>int. (by default None). Number of classes the diffusion model is trained of.</p>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="neural_de.transformations.diffusion.diffpure_config.DiffPureConfig.dims">
<span class="sig-name descname"><span class="pre">dims</span></span><a class="headerlink" href="#neural_de.transformations.diffusion.diffpure_config.DiffPureConfig.dims" title="Link to this definition"></a></dt>
<dd><p>int. images 1D, 2D or 3D (by default = 2)</p>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="neural_de.transformations.diffusion.diffpure_config.DiffPureConfig.learn_sigma">
<span class="sig-name descname"><span class="pre">learn_sigma</span></span><a class="headerlink" href="#neural_de.transformations.diffusion.diffpure_config.DiffPureConfig.learn_sigma" title="Link to this definition"></a></dt>
<dd><p>bool (by default = True). If true, the output channel number will be 6 instead
of 3.</p>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="neural_de.transformations.diffusion.diffpure_config.DiffPureConfig.num_channels">
<span class="sig-name descname"><span class="pre">num_channels</span></span><a class="headerlink" href="#neural_de.transformations.diffusion.diffpure_config.DiffPureConfig.num_channels" title="Link to this definition"></a></dt>
<dd><p>int (by default 256). Base channel number for the layers of the diffusion
model architecture.</p>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="neural_de.transformations.diffusion.diffpure_config.DiffPureConfig.num_head_channels">
<span class="sig-name descname"><span class="pre">num_head_channels</span></span><a class="headerlink" href="#neural_de.transformations.diffusion.diffpure_config.DiffPureConfig.num_head_channels" title="Link to this definition"></a></dt>
<dd><p>int (by default 64). Number of channel per head of the attention blocks.</p>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="neural_de.transformations.diffusion.diffpure_config.DiffPureConfig.num_res_blocks">
<span class="sig-name descname"><span class="pre">num_res_blocks</span></span><a class="headerlink" href="#neural_de.transformations.diffusion.diffpure_config.DiffPureConfig.num_res_blocks" title="Link to this definition"></a></dt>
<dd><p>int (by default 2). Number of residual block of the architecture.</p>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="neural_de.transformations.diffusion.diffpure_config.DiffPureConfig.resblock_updown">
<span class="sig-name descname"><span class="pre">resblock_updown</span></span><a class="headerlink" href="#neural_de.transformations.diffusion.diffpure_config.DiffPureConfig.resblock_updown" title="Link to this definition"></a></dt>
<dd><p>bool (by default True). Whether to apply a downsampling after each residual
block of the underlying Unet architecture.</p>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="neural_de.transformations.diffusion.diffpure_config.DiffPureConfig.use_fp16">
<span class="sig-name descname"><span class="pre">use_fp16</span></span><a class="headerlink" href="#neural_de.transformations.diffusion.diffpure_config.DiffPureConfig.use_fp16" title="Link to this definition"></a></dt>
<dd><p>bool (by default True). Use 16bit floating -point precision. If cuda is not
available, will be set as false (fp32).</p>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="neural_de.transformations.diffusion.diffpure_config.DiffPureConfig.use_scale_shift_norm">
<span class="sig-name descname"><span class="pre">use_scale_shift_norm</span></span><a class="headerlink" href="#neural_de.transformations.diffusion.diffpure_config.DiffPureConfig.use_scale_shift_norm" title="Link to this definition"></a></dt>
<dd><p>bool (by default True). Normalisation of the output of each block
of layers in the Unet architecture.</p>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="neural_de.transformations.diffusion.diffpure_config.DiffPureConfig.num_heads">
<span class="sig-name descname"><span class="pre">num_heads</span></span><a class="headerlink" href="#neural_de.transformations.diffusion.diffpure_config.DiffPureConfig.num_heads" title="Link to this definition"></a></dt>
<dd><p>int (by default 4). Number of attention heads.</p>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="neural_de.transformations.diffusion.diffpure_config.DiffPureConfig.num_heads_upsample">
<span class="sig-name descname"><span class="pre">num_heads_upsample</span></span><a class="headerlink" href="#neural_de.transformations.diffusion.diffpure_config.DiffPureConfig.num_heads_upsample" title="Link to this definition"></a></dt>
<dd><p>int (by default -1). Num head for upsampling attention layers.</p>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="neural_de.transformations.diffusion.diffpure_config.DiffPureConfig.channel_mult">
<span class="sig-name descname"><span class="pre">channel_mult</span></span><a class="headerlink" href="#neural_de.transformations.diffusion.diffpure_config.DiffPureConfig.channel_mult" title="Link to this definition"></a></dt>
<dd><p>tuple (by default None). Will be computed if not provided. Depending on the
resolution, multiply the base channel number to get the final one for each residual layer
of the Unet model.</p>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="neural_de.transformations.diffusion.diffpure_config.DiffPureConfig.dropout">
<span class="sig-name descname"><span class="pre">dropout</span></span><a class="headerlink" href="#neural_de.transformations.diffusion.diffpure_config.DiffPureConfig.dropout" title="Link to this definition"></a></dt>
<dd><p>float (by default 0.0). Dropout rate.</p>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="neural_de.transformations.diffusion.diffpure_config.DiffPureConfig.use_new_attention_order">
<span class="sig-name descname"><span class="pre">use_new_attention_order</span></span><a class="headerlink" href="#neural_de.transformations.diffusion.diffpure_config.DiffPureConfig.use_new_attention_order" title="Link to this definition"></a></dt>
<dd><p>bool (by default False). If true, the unet will use QKVAttention
layers, if False, will use QKVAttentionLegacy.</p>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="neural_de.transformations.diffusion.diffpure_config.DiffPureConfig.t">
<span class="sig-name descname"><span class="pre">t</span></span><a class="headerlink" href="#neural_de.transformations.diffusion.diffpure_config.DiffPureConfig.t" title="Link to this definition"></a></dt>
<dd><p>int (by default 150). Number of diffusion steps applied for each image.</p>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="neural_de.transformations.diffusion.diffpure_config.DiffPureConfig.t_delta">
<span class="sig-name descname"><span class="pre">t_delta</span></span><a class="headerlink" href="#neural_de.transformations.diffusion.diffpure_config.DiffPureConfig.t_delta" title="Link to this definition"></a></dt>
<dd><p>int (by default 15). Strength of the noise added before the diffusion process.</p>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="neural_de.transformations.diffusion.diffpure_config.DiffPureConfig.use_bm">
<span class="sig-name descname"><span class="pre">use_bm</span></span><a class="headerlink" href="#neural_de.transformations.diffusion.diffpure_config.DiffPureConfig.use_bm" title="Link to this definition"></a></dt>
<dd><p>float (by default False) #Erreur sur la valeur?</p>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="neural_de.transformations.diffusion.diffpure_config.DiffPureConfig.use_checkpoint">
<span class="sig-name descname"><span class="pre">use_checkpoint</span></span><a class="headerlink" href="#neural_de.transformations.diffusion.diffpure_config.DiffPureConfig.use_checkpoint" title="Link to this definition"></a></dt>
<dd><p>bool (by default False). gradient checkpointing for training</p>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="neural_de.transformations.diffusion.diffpure_config.DiffPureConfig.conv_resample">
<span class="sig-name descname"><span class="pre">conv_resample</span></span><a class="headerlink" href="#neural_de.transformations.diffusion.diffpure_config.DiffPureConfig.conv_resample" title="Link to this definition"></a></dt>
<dd><p>bool (by default True). Use learned convolutions for upsampling and
downsampling. If false, interpolation (nearest) will be used.</p>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="neural_de.transformations.diffusion.diffpure_config.DiffPureConfig.sample_step">
<span class="sig-name descname"><span class="pre">sample_step</span></span><a class="headerlink" href="#neural_de.transformations.diffusion.diffpure_config.DiffPureConfig.sample_step" title="Link to this definition"></a></dt>
<dd><p>int (by default 1). Number of time the diffusion process (noise addition +
denoising) is repeated for each image.</p>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="neural_de.transformations.diffusion.diffpure_config.DiffPureConfig.rand_t">
<span class="sig-name descname"><span class="pre">rand_t</span></span><a class="headerlink" href="#neural_de.transformations.diffusion.diffpure_config.DiffPureConfig.rand_t" title="Link to this definition"></a></dt>
<dd><p>bool (by default False). If true, add random noise before denoising. The noise is
sampled uniformly between -t_delta and +t_delta.</p>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="id0">
<span class="sig-name descname"><span class="pre">attention_resolutions</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><code class="xref py py-class docutils literal notranslate"><span class="pre">list</span></code><span class="pre">[</span><code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code><span class="pre">]</span></em><a class="headerlink" href="#id0" title="Link to this definition"></a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="id1">
<span class="sig-name descname"><span class="pre">channel_mult</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><code class="xref py py-class docutils literal notranslate"><span class="pre">tuple</span></code></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">None</span></em><a class="headerlink" href="#id1" title="Link to this definition"></a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="id2">
<span class="sig-name descname"><span class="pre">conv_resample</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">True</span></em><a class="headerlink" href="#id2" title="Link to this definition"></a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="id3">
<span class="sig-name descname"><span class="pre">dims</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">2</span></em><a class="headerlink" href="#id3" title="Link to this definition"></a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="id4">
<span class="sig-name descname"><span class="pre">dropout</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">0.0</span></em><a class="headerlink" href="#id4" title="Link to this definition"></a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="id5">
<span class="sig-name descname"><span class="pre">img_shape</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><code class="xref py py-class docutils literal notranslate"><span class="pre">tuple</span></code></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">(3,</span> <span class="pre">256,</span> <span class="pre">256)</span></em><a class="headerlink" href="#id5" title="Link to this definition"></a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="id6">
<span class="sig-name descname"><span class="pre">learn_sigma</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">True</span></em><a class="headerlink" href="#id6" title="Link to this definition"></a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="id7">
<span class="sig-name descname"><span class="pre">num_channels</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">256</span></em><a class="headerlink" href="#id7" title="Link to this definition"></a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="id8">
<span class="sig-name descname"><span class="pre">num_classes</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">None</span></em><a class="headerlink" href="#id8" title="Link to this definition"></a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="id9">
<span class="sig-name descname"><span class="pre">num_head_channels</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">64</span></em><a class="headerlink" href="#id9" title="Link to this definition"></a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="id10">
<span class="sig-name descname"><span class="pre">num_heads</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">4</span></em><a class="headerlink" href="#id10" title="Link to this definition"></a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="id11">
<span class="sig-name descname"><span class="pre">num_heads_upsample</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">-1</span></em><a class="headerlink" href="#id11" title="Link to this definition"></a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="id12">
<span class="sig-name descname"><span class="pre">num_res_blocks</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">2</span></em><a class="headerlink" href="#id12" title="Link to this definition"></a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="id13">
<span class="sig-name descname"><span class="pre">rand_t</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">False</span></em><a class="headerlink" href="#id13" title="Link to this definition"></a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="id14">
<span class="sig-name descname"><span class="pre">resblock_updown</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">True</span></em><a class="headerlink" href="#id14" title="Link to this definition"></a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="id15">
<span class="sig-name descname"><span class="pre">sample_step</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">1</span></em><a class="headerlink" href="#id15" title="Link to this definition"></a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="id16">
<span class="sig-name descname"><span class="pre">t</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">150</span></em><a class="headerlink" href="#id16" title="Link to this definition"></a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="id17">
<span class="sig-name descname"><span class="pre">t_delta</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">15</span></em><a class="headerlink" href="#id17" title="Link to this definition"></a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="id18">
<span class="sig-name descname"><span class="pre">use_bm</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">False</span></em><a class="headerlink" href="#id18" title="Link to this definition"></a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="id19">
<span class="sig-name descname"><span class="pre">use_checkpoint</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">False</span></em><a class="headerlink" href="#id19" title="Link to this definition"></a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="id20">
<span class="sig-name descname"><span class="pre">use_fp16</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">True</span></em><a class="headerlink" href="#id20" title="Link to this definition"></a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="id21">
<span class="sig-name descname"><span class="pre">use_new_attention_order</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">False</span></em><a class="headerlink" href="#id21" title="Link to this definition"></a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="id22">
<span class="sig-name descname"><span class="pre">use_scale_shift_norm</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">True</span></em><a class="headerlink" href="#id22" title="Link to this definition"></a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="id23">
<span class="sig-name descname"><span class="pre">weights_path</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><code class="xref py py-class docutils literal notranslate"><span class="pre">Path</span></code></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">PosixPath('/home/runner/.neuralde/diffpure/256x256_diffusion_uncond.pt')</span></em><a class="headerlink" href="#id23" title="Link to this definition"></a></dt>
<dd></dd></dl>

</dd></dl>

</section>
<section id="module-neural_de.transformations.diffusion.diffusion_enhancer">
<span id="neural-de-transformations-diffusion-diffusion-enhancer-module"></span><h2>neural_de.transformations.diffusion.diffusion_enhancer module<a class="headerlink" href="#module-neural_de.transformations.diffusion.diffusion_enhancer" title="Link to this heading"></a></h2>
<dl class="py class">
<dt class="sig sig-object py" id="neural_de.transformations.diffusion.diffusion_enhancer.DiffusionEnhancer">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">neural_de.transformations.diffusion.diffusion_enhancer.</span></span><span class="sig-name descname"><span class="pre">DiffusionEnhancer</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">device</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">config</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">DiffPureConfig(weights_path=PosixPath('/home/runner/.neuralde/diffpure/256x256_diffusion_uncond.pt'),</span> <span class="pre">img_shape=(3,</span> <span class="pre">256,</span> <span class="pre">256),</span> <span class="pre">attention_resolutions=[32,</span> <span class="pre">16,</span> <span class="pre">8],</span> <span class="pre">num_classes=None,</span> <span class="pre">dims=2,</span> <span class="pre">learn_sigma=True,</span> <span class="pre">num_channels=256,</span> <span class="pre">num_head_channels=64,</span> <span class="pre">num_res_blocks=2,</span> <span class="pre">resblock_updown=True,</span> <span class="pre">use_fp16=True,</span> <span class="pre">use_scale_shift_norm=True,</span> <span class="pre">num_heads=4,</span> <span class="pre">num_heads_upsample=-1,</span> <span class="pre">channel_mult=None,</span> <span class="pre">dropout=0.0,</span> <span class="pre">use_new_attention_order=False,</span> <span class="pre">t=150,</span> <span class="pre">t_delta=15,</span> <span class="pre">use_bm=False,</span> <span class="pre">use_checkpoint=False,</span> <span class="pre">conv_resample=True,</span> <span class="pre">sample_step=1,</span> <span class="pre">rand_t=False)</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">logger</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/neural_de/transformations/diffusion/diffusion_enhancer.html#DiffusionEnhancer"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#neural_de.transformations.diffusion.diffusion_enhancer.DiffusionEnhancer" title="Link to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="neural_de.transformations.html#neural_de.transformations.transformation.BaseTransformation" title="neural_de.transformations.transformation.BaseTransformation"><code class="xref py py-class docutils literal notranslate"><span class="pre">BaseTransformation</span></code></a></p>
<p>The goal of this class is to purify a batch of images, to reduce noise and to increase
robustness against potential adversarial attacks contained in the images. The weights given in
this librairy are adapted for an output in 256*256 format. Of course, all sizes are
supported in input but the enhancer will resize the images to 256*256.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>device</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">DeviceObjType</span></code>]) – some steps can be computed with cpu but a gpu is highly recommended.</p></li>
<li><p><strong>config</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code>[<a class="reference internal" href="#neural_de.transformations.diffusion.diffpure_config.DiffPureConfig" title="neural_de.transformations.diffusion.diffpure_config.DiffPureConfig"><code class="xref py py-class docutils literal notranslate"><span class="pre">DiffPureConfig</span></code></a>]) – an instance of the DiffPureConfig class. The most important attributes are: t,
sample_step and t_delta. Higher t or sample step will lead to a stronger denoising, at
the cost of processing time. t_delta is the quantity of noise added by the method before
it’s diffusion process : the higher, the higher the chances to remove adversarial attacks,
at the cost of a potentiel loss of quality in the images.
The other attributes of DiffPureConfig should be modified for a custom
Diffusion model.</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="neural_de.transformations.diffusion.diffusion_enhancer.DiffusionEnhancer.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/neural_de/transformations/diffusion/diffusion_enhancer.html#DiffusionEnhancer.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#neural_de.transformations.diffusion.diffusion_enhancer.DiffusionEnhancer.forward" title="Link to this definition"></a></dt>
<dd><p>Apply the diffusion process to a tensor of images.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>x</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code>) – Tensor of batch images</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Tensor of images after diffusion.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="neural_de.transformations.diffusion.diffusion_enhancer.DiffusionEnhancer.transform">
<span class="sig-name descname"><span class="pre">transform</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">image_batch</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/neural_de/transformations/diffusion/diffusion_enhancer.html#DiffusionEnhancer.transform"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#neural_de.transformations.diffusion.diffusion_enhancer.DiffusionEnhancer.transform" title="Link to this definition"></a></dt>
<dd><p>“Purify” (removes noise and noise-based adverserial attacks) a batch of input images by
applying a diffusion process to the images.</p>
<p>The images are resized to the diffusion model supported size (currently 256*256) :
you may want to resize/enhance the resolution of the output images. If the input images do
not have the same h and w, the resizing process will crop to a square image, thus losing
some information.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>image_batch</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">ndarray</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code>]) – Batch of images to purify (numpy array or torch.Tensor).</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>The batch of purified images (numpy array).</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>
<section id="module-neural_de.transformations.diffusion.rev_guided_diffusion">
<span id="neural-de-transformations-diffusion-rev-guided-diffusion-module"></span><h2>neural_de.transformations.diffusion.rev_guided_diffusion module<a class="headerlink" href="#module-neural_de.transformations.diffusion.rev_guided_diffusion" title="Link to this heading"></a></h2>
<dl class="py class">
<dt class="sig sig-object py" id="neural_de.transformations.diffusion.rev_guided_diffusion.RevGuidedDiffusion">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">neural_de.transformations.diffusion.rev_guided_diffusion.</span></span><span class="sig-name descname"><span class="pre">RevGuidedDiffusion</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">config</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">device</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">logger</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/neural_de/transformations/diffusion/rev_guided_diffusion.html#RevGuidedDiffusion"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#neural_de.transformations.diffusion.rev_guided_diffusion.RevGuidedDiffusion" title="Link to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code></p>
<p>Implements the rev-guided diffusion.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>device</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">DeviceObjType</span></code>]) – “cuda” or “cpu”. Gpu is highly recommended but somme steps are available with cpu.</p></li>
<li><p><strong>config</strong> (<a class="reference internal" href="#neural_de.transformations.diffusion.diffpure_config.DiffPureConfig" title="neural_de.transformations.diffusion.diffpure_config.DiffPureConfig"><code class="xref py py-class docutils literal notranslate"><span class="pre">DiffPureConfig</span></code></a>) – An instance of DiffPureConfig, it has been created in the input of the
DiffusionEhnancer class.</p></li>
<li><p><strong>logger</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">Logger</span></code>]) – logger.</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="neural_de.transformations.diffusion.rev_guided_diffusion.RevGuidedDiffusion.image_editing_sample">
<span class="sig-name descname"><span class="pre">image_editing_sample</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">img</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/neural_de/transformations/diffusion/rev_guided_diffusion.html#RevGuidedDiffusion.image_editing_sample"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#neural_de.transformations.diffusion.rev_guided_diffusion.RevGuidedDiffusion.image_editing_sample" title="Link to this definition"></a></dt>
<dd><p>This method apply the rev-guided diffusion to a batch of images.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>img</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code>) – Tensor (batch of images)</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Tensor (batch of images)</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="neural_de.transformations.diffusion.rev_guided_diffusion.RevGuidedDiffusion.training">
<span class="sig-name descname"><span class="pre">training</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code></em><a class="headerlink" href="#neural_de.transformations.diffusion.rev_guided_diffusion.RevGuidedDiffusion.training" title="Link to this definition"></a></dt>
<dd></dd></dl>

</dd></dl>

</section>
<section id="module-neural_de.transformations.diffusion.rev_vpsde">
<span id="neural-de-transformations-diffusion-rev-vpsde-module"></span><h2>neural_de.transformations.diffusion.rev_vpsde module<a class="headerlink" href="#module-neural_de.transformations.diffusion.rev_vpsde" title="Link to this heading"></a></h2>
<dl class="py class">
<dt class="sig sig-object py" id="neural_de.transformations.diffusion.rev_vpsde.RevVPSDE">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">neural_de.transformations.diffusion.rev_vpsde.</span></span><span class="sig-name descname"><span class="pre">RevVPSDE</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">beta_min</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">beta_max</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">20</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">N</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1000</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">img_shape</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">(3,</span> <span class="pre">256,</span> <span class="pre">256)</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">logger</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/neural_de/transformations/diffusion/rev_vpsde.html#RevVPSDE"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#neural_de.transformations.diffusion.rev_vpsde.RevVPSDE" title="Link to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code></p>
<p>Constructs a Variance Preserving SDE.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code>) – diffusion model</p></li>
<li><p><strong>beta_min</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code>) – min value of beta for normalisation</p></li>
<li><p><strong>beta_max</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code>) – max value of beta for normalisation</p></li>
<li><p><strong>N</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>) – scaling factor</p></li>
<li><p><strong>img_shape</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">tuple</span></code>) – Image dimension, channel-first.</p></li>
<li><p><strong>logger</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">Logger</span></code>]) – logger (logging.Logger)</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="neural_de.transformations.diffusion.rev_vpsde.RevVPSDE.f">
<span class="sig-name descname"><span class="pre">f</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">t</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">x</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/neural_de/transformations/diffusion/rev_vpsde.html#RevVPSDE.f"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#neural_de.transformations.diffusion.rev_vpsde.RevVPSDE.f" title="Link to this definition"></a></dt>
<dd><p>Creates the drift function -f(x, 1-t) (by t’ = 1 - t)
Sdeint only support a 2D tensor (batch_size, c*h*w)</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>t</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code>) – current step</p></li>
<li><p><strong>x</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code>) – batch of input images</p></li>
</ul>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="neural_de.transformations.diffusion.rev_vpsde.RevVPSDE.g">
<span class="sig-name descname"><span class="pre">g</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">t</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">x</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/neural_de/transformations/diffusion/rev_vpsde.html#RevVPSDE.g"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#neural_de.transformations.diffusion.rev_vpsde.RevVPSDE.g" title="Link to this definition"></a></dt>
<dd><p>Create the diffusion function g(1-t) (by t’ = 1 - t)
sdeint only support a 2D tensor (batch_size, c*h*w)</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>t</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code>) – current step</p></li>
<li><p><strong>x</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code>) – batch of input images</p></li>
</ul>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="neural_de.transformations.diffusion.rev_vpsde.RevVPSDE.rvpsde_fn">
<span class="sig-name descname"><span class="pre">rvpsde_fn</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">t</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">x</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">return_type</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'drift'</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/neural_de/transformations/diffusion/rev_vpsde.html#RevVPSDE.rvpsde_fn"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#neural_de.transformations.diffusion.rev_vpsde.RevVPSDE.rvpsde_fn" title="Link to this definition"></a></dt>
<dd><p>Create the drift and diffusion functions for the reverse SDE</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>t</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code>) – current step</p></li>
<li><p><strong>x</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code>) – batch of input images</p></li>
<li><p><strong>return_type</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>) – if “drift”, will apply a drift following the diffusion. If not, only the
diffusion will be performed.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="neural_de.transformations.diffusion.rev_vpsde.RevVPSDE.training">
<span class="sig-name descname"><span class="pre">training</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code></em><a class="headerlink" href="#neural_de.transformations.diffusion.rev_vpsde.RevVPSDE.training" title="Link to this definition"></a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="neural_de.transformations.diffusion.rev_vpsde.RevVPSDE.vpsde_fn">
<span class="sig-name descname"><span class="pre">vpsde_fn</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">t</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">x</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/neural_de/transformations/diffusion/rev_vpsde.html#RevVPSDE.vpsde_fn"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#neural_de.transformations.diffusion.rev_vpsde.RevVPSDE.vpsde_fn" title="Link to this definition"></a></dt>
<dd><p>Apply variant-preserving sde to a batch of images.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>timesteps</strong> – current timestep</p></li>
<li><p><strong>x</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code>) – image batch</p></li>
</ul>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">tuple</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code>]</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>
<section id="module-neural_de.transformations.diffusion">
<span id="module-contents"></span><h2>Module contents<a class="headerlink" href="#module-neural_de.transformations.diffusion" title="Link to this heading"></a></h2>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="neural_de.transformations.html" class="btn btn-neutral float-left" title="neural_de.transformations package" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="neural_de.transformations.diffusion.unet.html" class="btn btn-neutral float-right" title="neural_de.transformations.diffusion.unet package" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2025, IRT-SystemX.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>